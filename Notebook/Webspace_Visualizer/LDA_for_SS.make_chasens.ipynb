{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import MeCab\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../MyPythonModule\")\n",
    "import mymodule\n",
    "sys.path.append(\"../../Webspace_Visualizer/Webspace_Visualizer\")\n",
    "from LDA_kai import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def suffix_generator(target=None,is_largest=False):\n",
    "    suffix = \"\"\n",
    "    if target != None:\n",
    "        suffix += \"_\" + target\n",
    "    if is_largest == True:\n",
    "        suffix += \"_largest\"\n",
    "    return suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    re_url = re.compile(\"((https?|ftp)(:\\/\\/[-_.!~*\\'()a-zA-Z0-9;\\/?:\\@&=+\\$,%#]+))\")\n",
    "    return re_url.sub(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_textfile(text):\n",
    "    words = []\n",
    "    \"\"\"urlの除外\"\"\"\n",
    "    text = remove_url(text)\n",
    "\n",
    "    m = MeCab.Tagger(\"-Ochasen\")\n",
    "    m.parse('') # <= 空文字列をparseする．これがないとsurfaceがとれないバグ発生？\n",
    "    node = m.parseToNode(text.encode(\"utf8\"))\n",
    "    node = node.next\n",
    "    while node:\n",
    "        part = unicode(node.feature,(\"utf-8\"))\n",
    "        partlist = part.split(\",\")\n",
    "        if partlist[0] == u\"名詞\" and (partlist[1]== u\"一般\" or partlist[1]== u\"固有名詞\"):\n",
    "            doc = unicode(node.surface,\"utf-8\")\n",
    "            if re.match(\"^[a-zA-Z0-9]$\",doc) == None:#アルファベットや数字単体の場合は除外\n",
    "                words.append(doc)\n",
    "        node = node.next\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\u540d\\u524d', u'\\u7530\\u4e2d', u'\\u592a\\u90ce']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"私の名前は田中太郎です。\".decode(\"utf-8\")\n",
    "load_textfile(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_target(json_dict):\n",
    "    if len(json_dict[\"text2B\"]) > 100:\n",
    "        return json_dict[\"text2B\"]\n",
    "    else:\n",
    "        return json_dict[\"myexttext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_word = u\"iPhone\"\n",
    "max_page = 10\n",
    "root_dir = \"../Data/Search_\" + search_word + \"_\" + unicode(max_page) + \"_add_childs\" \n",
    "is_largest = True\n",
    "target = \"myexttext\"\n",
    "G_name = \"G\" + suffix_generator(target=target,is_largest=is_largest)\n",
    "use_to_link = \"to_ext_links\"\n",
    "K = 10\n",
    "iteration = 50\n",
    "alpha = 0.001\n",
    "beta = 0.001\n",
    "no_below = 5#単語の最低出現文書数\n",
    "no_above = 0.2#単語の最大出現文書比率\n",
    "no_less = 20#文書に含まれる最低単語数\n",
    "do_hparam_update = False#パラメータを更新するか否か\n",
    "chasen_dir_name = \"Chasen\" + suffix_generator(target,is_largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_id_list = []\n",
    "if is_largest == True:\n",
    "    with open(os.path.join(root_dir,\"file_id_list.list\")) as fi:#収集したwebページのうち，実際に使用する対象のリスト．リンクを持っていないものなどを省く\n",
    "       file_id_list=pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chasen_dir = os.path.join(root_dir,chasen_dir_name)\n",
    "if not os.path.exists(chasen_dir):\n",
    "    os.mkdir(chasen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.json',\n",
       " u'1.json',\n",
       " u'2.json',\n",
       " u'3.json',\n",
       " u'4.json',\n",
       " u'5.json',\n",
       " u'6.json',\n",
       " u'7.json',\n",
       " u'8.json',\n",
       " u'9.json',\n",
       " u'10.json',\n",
       " u'11.json',\n",
       " u'12.json',\n",
       " u'13.json',\n",
       " u'14.json',\n",
       " u'15.json',\n",
       " u'16.json',\n",
       " u'17.json',\n",
       " u'18.json',\n",
       " u'19.json',\n",
       " u'20.json',\n",
       " u'21.json',\n",
       " u'22.json',\n",
       " u'23.json',\n",
       " u'24.json',\n",
       " u'25.json',\n",
       " u'26.json',\n",
       " u'27.json',\n",
       " u'28.json',\n",
       " u'29.json',\n",
       " u'30.json',\n",
       " u'31.json',\n",
       " u'32.json',\n",
       " u'33.json',\n",
       " u'34.json',\n",
       " u'35.json',\n",
       " u'36.json',\n",
       " u'37.json',\n",
       " u'38.json',\n",
       " u'39.json',\n",
       " u'40.json',\n",
       " u'41.json',\n",
       " u'42.json',\n",
       " u'43.json',\n",
       " u'44.json',\n",
       " u'45.json',\n",
       " u'46.json',\n",
       " u'47.json',\n",
       " u'48.json',\n",
       " u'49.json',\n",
       " u'50.json',\n",
       " u'51.json',\n",
       " u'52.json',\n",
       " u'53.json',\n",
       " u'54.json',\n",
       " u'55.json',\n",
       " u'56.json',\n",
       " u'57.json',\n",
       " u'58.json',\n",
       " u'59.json',\n",
       " u'60.json',\n",
       " u'61.json',\n",
       " u'62.json',\n",
       " u'63.json',\n",
       " u'64.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_dir = os.path.join(root_dir,\"Pages\")\n",
    "files = os.listdir(pages_dir)\n",
    "files = [file for file in files if os.path.splitext(file)[1] == \".json\"]\n",
    "mymodule.sort_nicely(files)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_list = file_id_list\n",
    "if target_list == []:\n",
    "    file_id_dict = dict(zip(range(len(files)),range(len(files))))\n",
    "else:\n",
    "    files = [files[i] for i in target_list]\n",
    "    file_id_dict = dict(zip(range(len(files)),target_list))#LDAでの文書番号をKEYに，実際の文書名の番号をvalueに持った辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 2,\n",
       " 2: 3,\n",
       " 3: 4,\n",
       " 4: 5,\n",
       " 5: 6,\n",
       " 6: 7,\n",
       " 7: 9,\n",
       " 8: 10,\n",
       " 9: 11,\n",
       " 10: 12,\n",
       " 11: 13,\n",
       " 12: 14,\n",
       " 13: 15,\n",
       " 14: 16,\n",
       " 15: 17,\n",
       " 16: 18,\n",
       " 17: 19,\n",
       " 18: 20,\n",
       " 19: 21,\n",
       " 20: 22,\n",
       " 21: 23,\n",
       " 22: 24,\n",
       " 23: 25,\n",
       " 24: 26,\n",
       " 25: 27,\n",
       " 26: 28,\n",
       " 27: 29,\n",
       " 28: 30,\n",
       " 29: 31,\n",
       " 30: 32,\n",
       " 31: 33,\n",
       " 32: 34,\n",
       " 33: 35,\n",
       " 34: 36,\n",
       " 35: 37,\n",
       " 36: 38,\n",
       " 37: 39,\n",
       " 38: 40,\n",
       " 39: 41,\n",
       " 40: 42,\n",
       " 41: 43,\n",
       " 42: 44,\n",
       " 43: 45,\n",
       " 44: 46,\n",
       " 45: 47,\n",
       " 46: 48,\n",
       " 47: 49,\n",
       " 48: 50,\n",
       " 49: 51,\n",
       " 50: 52,\n",
       " 51: 53,\n",
       " 52: 56}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,file in enumerate(files):\n",
    "    with open(os.path.join(pages_dir,file),\"r\") as fj:\n",
    "        json_dict = json.load(fj)\n",
    "    if target == \"hybrid\":\n",
    "        doc = load_textfile(select_target(json_dict))\n",
    "    else:\n",
    "        doc = load_textfile(json_dict[target])\n",
    "\n",
    "    \"\"\"実際に使うテキストの単語群を書き出し\"\"\"\n",
    "    with open(os.path.join(chasen_dir,os.path.splitext(file)[0]+\".txt\"),\"w\") as fo:\n",
    "        for word in doc:\n",
    "            print >> fo,word.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(root_dir,\"file_id_dict.dict\"),\"w\") as fo:\n",
    "    pickle.dump(file_id_dict,fo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
